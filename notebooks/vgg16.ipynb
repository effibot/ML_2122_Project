{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "We will try to train a neural network to see if we can get better results. We will try to use a model created by the Visual Geometry Group (VGG) at Oxford. We will use the VGG16 model which contains 16 layers (13 convolutional layers and 3 fully connected layers).\n",
    "\n",
    "Our first attempt will be to use the model with our dataset without any modification, then we will try to perform some data augmentation to see if we can get better results.\n",
    "![](../doc/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Colab backend\n",
    "from colabcode import ColabCode\n",
    "ColabCode(port=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Rescaling\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "  assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lion (Evo**L**ved S**i**gned M**o**me**n**tum) optimizer ([paper](https://arxiv.org/abs/2302.06675))\n",
    "\n",
    "We will use the Lion optimizer to train the model. It's a new optimizer that combines the advantages of the Adam and SGD optimizers. It's a momentum-based optimizer that uses the first and second moments of the gradient to update the parameters. The performance of the optimizer is comparable to Adam and SGD, but it's faster and more memory efficient.\n",
    "\n",
    "The implementation comes from this [GitHub](https://github.com/GLambard/Lion-tensorflow/blob/main/lion_tensorflow.py) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "from typing import Tuple, Optional, Callable\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "# update functions\n",
    "\n",
    "@tf.function\n",
    "def update_fn(p, grad, exp_avg, lr, wd, beta1, beta2):\n",
    "    # stepweight decay\n",
    "\n",
    "    p.assign(p * (1 - lr * wd))\n",
    "\n",
    "    # weight update\n",
    "\n",
    "    update = tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0]*exp_avg + (1 - tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0])*grad\n",
    "    p.assign_add(tf.sign(update) * -lr)\n",
    "\n",
    "    # decay the momentum running average coefficient\n",
    "\n",
    "    exp_avg.assign(exp_avg * beta2 + grad * (1 - beta2))\n",
    "\n",
    "# class\n",
    "\n",
    "class Lion(optimizers.Optimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float = 1e-4,\n",
    "        betas: Tuple[float, float] = (0.9, 0.99),\n",
    "        weight_decay: float = 0.0,\n",
    "        use_triton: bool = False,\n",
    "        name: str = \"Lion\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        assert lr > 0.\n",
    "        assert all([0. <= beta <= 1. for beta in betas])\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.update_fn = update_fn\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'lr': self.lr,\n",
    "            'betas': self.betas,\n",
    "            'weight_decay': self.weight_decay\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        lr = self.lr\n",
    "        beta1 = self.betas[0]\n",
    "        beta2 = self.betas[1]\n",
    "        wd = self.weight_decay\n",
    "\n",
    "        # init state - exponential moving average of gradient values\n",
    "        exp_avg = self.get_slot(var, \"exp_avg\")\n",
    "        if exp_avg is None:\n",
    "            exp_avg = self.add_slot(var, \"exp_avg\", tf.zeros_like(var))\n",
    "\n",
    "        self.update_fn(\n",
    "            var,\n",
    "            grad,\n",
    "            exp_avg,\n",
    "            lr,\n",
    "            wd,\n",
    "            beta1,\n",
    "            beta2\n",
    "        )\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")\n",
    "\n",
    "    def _resource_apply_sparse_duplicate_indices(self, grad, var, indices):\n",
    "        raise NotImplementedError(\"Sparse gradient updates are not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "vgg16 = Sequential([\n",
    "        # Preprocessing stack\n",
    "        Rescaling(1./255, input_shape=(224, 224, 3)),\n",
    "        # 1st stack\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        # 2nd stack\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        # 3rd stack\n",
    "        Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(256, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # 4th stack\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # 5th stack\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        Conv2D(512, (3, 3), padding = 'same', activation = 'relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        # 6th stack\n",
    "        Flatten(),\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        # 7th stack\n",
    "        Dense(4096, activation = 'relu'),\n",
    "        Dropout(0.5),\n",
    "        # 8th stack\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ]\n",
    ")\n",
    "#lion = Lion(lr=1e-3)\n",
    "# Compile the model with Lion optimizer\n",
    "vgg16.compile(optimizer=optimizers.RMSprop(learning_rate = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 files belonging to 2 classes.\n",
      "Using 19291 files for training.\n",
      "Found 27558 files belonging to 2 classes.\n",
      "Using 8267 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load the data using tensorflow utilities\n",
    "root = \"../data\"\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    root,\n",
    "    validation_split=0.3,\n",
    "    subset='training',\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    root,\n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 134,264,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Configure the dataset for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi Ã¨ verificato un arresto anomalo del kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. Esaminare il codice nelle celle per identificare una possibile causa dell'errore. Per altre informazioni, fare clic su <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a>. Per altri dettagli, vedere Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = vgg16.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Perform data augmentation\n",
    "\n",
    "To improve the model performance, we will perform data augmentation on the training set. We will use the following transformations:\n",
    "\n",
    "- Rotation\n",
    "- Zoom\n",
    "- Horizontal and Vertical Flips\n",
    "- Width and Height Shifts\n",
    "- Shear Transformation\n",
    "- Brightness\n",
    "- Contrast\n",
    "- Gaussian Noise\n",
    "- Gaussian Blur\n",
    "- Motion Blur\n",
    "- Median Blur\n",
    "- Random Crop\n",
    "- To Gray\n",
    "- Coarse Dropout\n",
    "- Invert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the Keras ImageDataGenerator to augment the data\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create an instance of the ImageDataGenerator\n",
    "#datagen = ImageDataGenerator()\n",
    "# fit the generator to the data - this will calculate the mean and std of the data\n",
    "#datagen.fit(X_train)\n",
    "## get a batch iterator to efficiently iterate over the training data\n",
    "#train_iterator = datagen.flow(X_train, y_train, batch_size=32)\n",
    "## get a batch iterator for the validation data\n",
    "#val_iterator = datagen.flow(X_val, y_val, batch_size=32)\n",
    "## fit the model\n",
    "#mod\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
